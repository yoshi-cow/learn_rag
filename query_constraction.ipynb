{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG関連手法の学習 - 3. Query Construction\n",
    "* https://python.langchain.com/docs/concepts/#retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from PIL import Image\n",
    "# 環境変数読み込み\n",
    "load_dotenv()\n",
    "\n",
    "# 画像表示関数\n",
    "def show_image(path):\n",
    "    im = Image.open(path)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Query Constuction\n",
    "Using an LLM to convert a natural language query into a query syntax is a popular and powerful approach.\n",
    "\n",
    "1. **Text to SQL**\n",
    "    * If users are asking questions that require information housed in a relational database, accessible via SQL.\n",
    "    * This uses an LLM to transform user input into a SQL query.\n",
    "    * https://python.langchain.com/docs/tutorials/sql_qa/\n",
    "2. **Text-to-Cypher**\n",
    "    * If users are asking questions that require information housed in a graph database, accessible via Cypher.\n",
    "    * This uses an LLM to transform user input into a Cypher query.\n",
    "    * https://python.langchain.com/docs/tutorials/graph/\n",
    "3. **Self Query**\n",
    "    * If users are asking questions that are better answered by fectching documents based on metadata rather than similarity with the text.\n",
    "    * This uses an LLM to transform user input into two things: (1) a string to look up semantically, (2) a metadata filter to go along with it. This is useful because oftentimes questions are about the MEATADATA of documents (not the content itself).\n",
    "    * https://python.langchain.com/docs/how_to/self_query/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. Text to SQL\n",
    "* https://python.langchain.com/docs/tutorials/sql_qa/\n",
    "\n",
    "* Enabling a LLM system to query structured data can be qualitatively different from unstructured text data. Whereas in the latter it is common to generate text that can be searched against a vector database, the approach for structured data is often for the LLM to write and execute queries in a DSL, such as SQL. In this guide we'll go over the basic ways to create a Q&A system over tabular data in databases. We will cover implementations using both chains and agents. These systems will allow us to ask a question about the data in a database and get back a natural language answer. The main difference between the two is that our agent can query the database in a loop as many times as it needs to answer the question.\n",
    "\n",
    "#### Architecture\n",
    "At a high-level, the steps of these systems are:\n",
    "\n",
    "1. Convert question to DSL query: Model converts user input to a SQL query.\n",
    "2. Execute SQL query: Execute the query.\n",
    "3. Answer the question: Model responds to user input using the query results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['albums', 'artists', 'customers', 'employees', 'genres', 'invoice_items', 'invoices', 'media_types', 'playlist_track', 'playlists', 'tracks']\n"
     ]
    }
   ],
   "source": [
    "### prepare SQL Database\n",
    "\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "db = SQLDatabase.from_uri(\"sqlite:////Users/user/for_IT/learn_rag/data/chinook.db\")\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'Antônio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run(\"SELECT * FROM artists LIMIT 10;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chains\n",
    "1. convert the question into a SQL query\n",
    "2. execute the query\n",
    "3. use the result to answer the original question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1. convert the question into a SQL query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SQLQuery: SELECT COUNT(\"EmployeeId\") AS \"EmployeeCount\" FROM employees;'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "\n",
    "from langchain.chains import create_sql_query_chain\n",
    "chain = create_sql_query_chain(llm, db)\n",
    "response = chain.invoke({\"question\": \"How many employees are there\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. execute the query\n",
    "\n",
    "Now that we've generated a SQL query, we'll want to execute it. **This is the most dangerous part of creating a SQL chain**. Consider carefully if it is OK to run automated queries over your data. Minimize the database connection permissions as much as possible. Consider adding a human approval step to you chains before query execution (see below).\n",
    "\n",
    "We can use the QuerySQLDatabaseTool to easily add query execution to our chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='SELECT COUNT(\"EmployeeId\") AS \"EmployeeCount\" FROM employees;', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 85, 'total_tokens': 99, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f85bea6784', 'finish_reason': 'stop', 'logprobs': None}, id='run-c56c2395-42d4-43c4-b28a-8b322d7875db-0', usage_metadata={'input_tokens': 85, 'output_tokens': 14, 'total_tokens': 99, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 上記では、SQL文に余計な文字が入るので、以下のように、整形するtemplateを追加する。\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "sql_mod_tmt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a great database engineer. Please make SQL for query.\n",
    "    Answer is just SQL only and don't add any word expect for SQL like following example.\n",
    "    error: 'sql\\nSELECT A fFROM table;'\n",
    "    correct: 'SELECT A fFROM table;'\n",
    "\n",
    "    Question: {input}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain = create_sql_query_chain(llm, db) | sql_mod_tmt | llm\n",
    "response = chain.invoke ({\"question\": \"How many employees are there\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COUNT(\"EmployeeId\") AS \"EmployeeCount\" FROM employees;\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8,)]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# SQLクエリ実行用\n",
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "# AIMessageからSQLクエリを抽出するランナブル\n",
    "extract_sql_query = RunnableLambda(lambda x: x.content)\n",
    "\n",
    "# SQL作成と検索用chain\n",
    "chain = (create_sql_query_chain(llm, db)\n",
    "         | sql_mod_tmt\n",
    "         | llm\n",
    "         | extract_sql_query\n",
    "         | execute_query\n",
    ")\n",
    "# 実行\n",
    "result = chain.invoke({\"question\": \"How many employees are there\"})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. answer the question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are 8 employees.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "write_query = (create_sql_query_chain(llm, db)\n",
    "         | sql_mod_tmt\n",
    "         | llm\n",
    "         | extract_sql_query\n",
    ")\n",
    "\n",
    "answer_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Result: {result}\n",
    "Answer: \"\"\"\n",
    ")\n",
    "\n",
    "final_chain = (\n",
    "    RunnablePassthrough.assign(query=write_query).assign(\n",
    "        result=itemgetter(\"query\") | execute_query\n",
    "    )\n",
    "    | answer_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_chain.invoke({\"question\": \"How many employees are there\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. Text-to-Cypher\n",
    "* https://python.langchain.com/docs/tutorials/graph/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
